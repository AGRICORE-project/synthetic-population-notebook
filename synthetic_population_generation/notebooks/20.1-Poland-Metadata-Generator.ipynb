{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir(\"/home/jovyan/work/carlos/complete_execution_andalucia\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.chdir(\"./../\")\n",
    "#from src.VariableNameConversion import VariableNameConversion\n",
    "#os.chdir(\"./notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region: Lublin\n",
    "NUTS2_code = \"PL81\"\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microdata_path = \"./data/use_case_poland/microdata\"\n",
    "\n",
    "microdata = pd.DataFrame()\n",
    "\n",
    "for file in sorted(os.listdir(microdata_path)):\n",
    "    if file != \"POL2030.csv\" and not file.startswith(\"PL\"):\n",
    "        print(file)\n",
    "        df_ = pd.read_csv(os.path.join(microdata_path, file))\n",
    "\n",
    "        if file in [\"POL2014.csv\", \"POL2015.csv\", \"POL2016.csv\"]:\n",
    "            nuts2_code_ = \"PL31\"\n",
    "        else:\n",
    "            nuts2_code_ = NUTS2_code\n",
    "\n",
    "        # Compose an unique df with all the years\n",
    "        microdata = pd.concat([microdata, df_])\n",
    "\n",
    "        print(nuts2_code_)\n",
    "\n",
    "        # Save only required NUTS\n",
    "        selection = df_[df_[\"A_LO_40_N2\"]==nuts2_code_]\n",
    "        \n",
    "        selection[\"A_LO_40_N2\"] = selection[\"A_LO_40_N2\"].apply(lambda x: NUTS2_code)\n",
    "        print(selection.shape)\n",
    "        \n",
    "        selection.to_csv(f'./data/use_case_poland/microdata/{file.replace(\"POL\", \"PL\")}', index=False)\n",
    "        \n",
    "microdata[\"YEAR\"] = 2030\n",
    "\n",
    "microdata.reset_index(drop=True).to_csv(\"./data/use_case_poland/microdata/POL2030.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Minimum economic size: {microdata[\"SE005\"].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_by_crop_filepath = \"./\"# Set path\n",
    "\n",
    "os.listdir(totals_by_crop_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(totals_by_crop_filepath, \"Poland-crops-totals\"), sep=\",|\\t\")\n",
    "\n",
    "metadata[\"geo\\\\TIME_PERIOD\"] = metadata.apply(lambda x: NUTS2_code, axis=1)\n",
    "\n",
    "\n",
    "metadata = metadata[metadata[\"geo\\\\TIME_PERIOD\"].isin([NUTS2_code])]\n",
    "\n",
    "\n",
    "#data = data[[\"crops\", \"unit\", \"geo\\TIME_PERIOD\", \"2005 \", \"2007 \", \"2010 \", \"2013 \", \"2016 \", \"2020\", ]]\n",
    "metadata = metadata[[\"crops\", \"unit\", \"2013 \", \"2016 \", \"2020\"]].rename(columns={\"2013 \": \"2013\", \"2016 \": \"2016\"})\n",
    "\n",
    "\n",
    "for c in [\"2013\", \"2016\", \"2020\"]:\n",
    "    metadata[c] = metadata.apply(lambda x: x[c].replace(\" \", \"\").replace(\":\", \"\").replace(\"c\", \"\").replace(\"u\", \"\"), axis=1)\n",
    "    metadata[c] = metadata.apply(lambda x: \"0\" if x[c]==\"\" else x[c], axis=1)\n",
    "    metadata[c] = metadata[c].astype(int)\n",
    "\n",
    "metadata = metadata.groupby(by=[\"crops\", \"unit\"]).sum().reset_index()\n",
    "\n",
    "display(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for crop in metadata[\"crops\"].unique():\n",
    "    print(f'\"{crop}\": \"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = {\n",
    "    #\"UAA\": \"Utilised agricultural area\",\n",
    "    #\"UAA09S\": \"Other utilised agricultural area n.e.c. - under glass or high accessible cover\",\n",
    "    #\"UAAT\": \"Utilised agricultural area - outdoor\",\n",
    "    #\"UAAS\": \"Utilised agricultural area - under glass or high accessible cover\",\n",
    "    #\"ARA09S\": \"Other arable land crops n.e.c. - under glass or high accessible cover\",\n",
    "    #\"ARA\": \"Arable land\",\n",
    "    #\"C0000\": \"Cereals for the production of grain (including seed)\",\n",
    "    \"C1110\": \"Common wheat and spelt\",\n",
    "    \"C1120\": \"Durum wheat\",\n",
    "    \"C1200\": \"Rye\", #\"Rye and winter cereal mixtures (maslin)\",\n",
    "    \"C1300\": \"Barley\",\n",
    "    \"C1400\": \"Oats\", #\"Oats and spring cereal mixtures (mixed grain other than maslin)\",\n",
    "    \"C1500\": \"Grain maize\", #\"Grain maize and corn-cob-mix\",\n",
    "    \"C1600_1700_1900\": \"Other cereals for the production of grain\", #\"Other cereals (including triticale and sorghum)\",\n",
    "    \"C2000\": \"Rice\",\n",
    "    #\"P0000\": \"Dry pulses and protein crops for the production of grain (including seed and mixtures of cereals and pulses)\",\n",
    "    \"P1000\": \"Peas, field beans and sweet lupines\", #\"Field peas, beans and sweet lupins\",\n",
    "    #\"P9000\": \"Other dry pulses and protein crops n.e.c.\",\n",
    "    #\"R0000\": \"Root crops\",\n",
    "    \"R1000\": \"Potatoes (including early potatoes and seed potatoes)\", #\"Potatoes (including seed potatoes)\",\n",
    "    \"R2000\": \"Sugar beet (excluding seed)\",\n",
    "    \"R9000\": \"Fodder roots and brassicas (excluding seed)\", #\"Other root crops n.e.c.\",\n",
    "    #\"I0000\": \"Industrial crops\",\n",
    "    \"I1110\": \"Rape and turnip rape\", #\"Rape and turnip rape seeds\",\n",
    "    \"I1120\": \"Sunflower\", #\"Sunflower seed\",\n",
    "    \"I1130\": \"Soya\",\n",
    "    \"I1140\": \"Linseed (oil flax)\", #\"Linseed (oilflax)\",\n",
    "    \"I1150_2300\": \"Cotton\", #\"Cotton seed and fibre\",\n",
    "    \"I1190\": \"Other oil seed crops\", #\"Other oilseed crops n.e.c.\",\n",
    "    #\"I2000\": \"Fibre crops\",\n",
    "    \"I2100\": \"Fibre flax\",\n",
    "    \"I2200\": \"Hemp\",\n",
    "    \"I2900\": \"Other fibre plants\", #\"Other fibre crops n.e.c.\",\n",
    "    \"I3000\": \"Tobacco\",\n",
    "    \"I4000\": \"Hops\",\n",
    "    \"I5000\": \"Aromatic plants, medical and culinary plants\", #\"Aromatic, medicinal and culinary plants\",\n",
    "    #\"I6000_9000\": \"Other industrial crops not mentioned elsewhere\", #\"Other industrial crops including energy crops n.e.c.\",\n",
    "    \"I9000\": \"Other industrial crops not mentioned elsewhere\", #\"Other industrial crops n.e.c.\",\n",
    "    #\"G0000\": \"Plants harvested green from arable land\",\n",
    "    \"G0000X1000\": \"Plants harvested green from arable land excluding temporary grasses and grazings\",\n",
    "    \"G1000\": \"Temporary grasses and grazings\",\n",
    "    \"G2000\": \"Leguminous plants\", #\"Leguminous plants harvested green\",\n",
    "    \"G3000\": \"Green maize\",\n",
    "    \"G9000\": \"Other plants harvested green from arable land\",\n",
    "    \"G9100\": \"Other plants harvested green but not mentioned elsewhere\", #\"Other cereals harvested green (excluding green maize)\",\n",
    "    \"G9900\": \"Other plants harvested green from arable land n.e.c.\",\n",
    "    #\"V0000_S0000\": \"Fresh vegetables (including melons) and strawberries\",\n",
    "    #\"V0000_S0000T\": \"Fresh vegetables (including melons) and strawberries - outdoor\",\n",
    "    \"V0000_S0000TO\": \"Fresh vegetables, melons and strawberries -Open field\", #\"Fresh vegetables (including melons) and strawberries grown in rotation with non-horticultural crops (open field)\",\n",
    "    \"V0000_S0000TK\": \"Fresh vegetables, melons and strawberries -Market gardening\", #\"Fresh vegetables (including melons) and strawberries grown in rotation with horticultural crops (market gardening)\",\n",
    "    \"V0000_S0000S\": \"Fresh vegetables, melons and strawberries -Under glass or under other (accessible) protective cover.\", #\"Fresh vegetables (including melons) and strawberries - under glass or high accessible cover\",\n",
    "    #\"N0000\": \"Flowers and ornamental plants (excluding nurseries)\",\n",
    "    \"N0000T\": \"Flowers and ornamental plants -Outdoor or under low protective cover\", #\"Flowers and ornamental plants (excluding nurseries) - outdoor\",\n",
    "    \"N0000S\": \"Flowers and ornamental plants -Under glass or under other protective cover\", #\"Flowers and ornamental plants (excluding nurseries) - under glass or high accessible cover\",\n",
    "    \"E0000\": \"Arable land seed and seedling\", #\"Seeds and seedlings\",\n",
    "    \"ARA99\": \"Other arable land crops n.e.c.\",\n",
    "    #\"Q0000\": \"Fallow land\",\n",
    "    #\"J0000\": \"Permanent grassland\",\n",
    "    \"J1000\": \"Permanent pastures and meadows\",\n",
    "    \"J2000\": \"Permanent rough grazings\",\n",
    "    \"J3000TE\": \"Permanent agricultural grassland not in use, eligible for subsidies - outdoor\",\n",
    "    \"PECR\": \"Permanent crops\",\n",
    "    \"PECRT\": \"Permanent crops - outdoor\",\n",
    "    \"PECRS\": \"Permanent crops under glass or high accessible cover\",\n",
    "    \"F0000\": \"Fruits, berries and nuts (excluding citrus fruits, grapes and strawberries)\",\n",
    "    \"F1000_2000\": \"Fruits from temperate, subtropical and tropical climate zones\",\n",
    "    \"F1000\": \"Fruits from temperate climate zones\",\n",
    "    #\"F1100\": \"Pome fruits\",\n",
    "    #\"F1200\": \"Stone fruits\",\n",
    "    \"F2000\": \"Fruits from subtropical and tropical climate zones\",\n",
    "    \"F3000\": \"Berries (excluding strawberries)\",\n",
    "    \"F4000\": \"Nuts\",\n",
    "    #\"T0000\": \"Citrus fruits\",\n",
    "    \"W1000\": \"Grapes\",\n",
    "    \"W1100\": \"Grapes for wines\",\n",
    "    \"W1110_1120\": \"Grapes for wines with geographical indication (PDO/PGI)\",\n",
    "    \"W1110\": \"Grapes for wines with protected designation of origin (PDO)\",\n",
    "    \"W1120\": \"Grapes for wines with protected geographical indication (PGI)\",\n",
    "    \"W1190\": \"Grapes for other wines n.e.c. (without PDO/PGI)\",\n",
    "    \"W1200\": \"Grapes for table use\",\n",
    "    \"W1300\": \"Grapes for raisins\",\n",
    "    #\"O1000\": \"Olives\",\n",
    "    \"O1100\": \"Table olives\", #\"Olives for table use\",\n",
    "    \"O1910\": \"Olives for oil production (sold in the form of fruit)\", #\"Olives for oil\",\n",
    "    \"L0000\": \"Nurseries\",\n",
    "    \"PECR9_H9000\": \"Other permanent crops including other permanent crops for human consumption\",\n",
    "    \"X0000\": \"Other permanent crops, of which Christmas tress\", #\"Christmas trees\",\n",
    "    \"U1000\": \"Mushrooms\", #\"Cultivated mushrooms\",\n",
    "    \"SRCAA\": \"Short rotation coppice areas\"\n",
    "}\n",
    "\n",
    "links_inv = dict(zip(links.values(), links.keys()))\n",
    "\n",
    "print(links_inv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load FADN individual codes\n",
    "Use Andalusia product mapping to load individual FADN codes and their description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_mapping_and = pd.read_csv(\"./data/use_case_andalusia/metadata/Product_Mapping.csv\")\n",
    "\n",
    "product_mapping = product_mapping_and.copy(deep=True)[[\"FADN Included products\", \"FADN Included products IDs\"]].drop_duplicates()\n",
    "product_mapping.at[24, \"FADN Included products\"] = \"Fibre flax\"\n",
    "product_mapping.at[18, \"FADN Included products\"] = \"Cotton\"\n",
    "\n",
    "product_mapping.iloc[[22, 23, 24]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_mapping[\"col\"] = product_mapping.apply(lambda x: links_inv[x[\"FADN Included products\"]] if x[\"FADN Included products\"] in links_inv.keys() else np.nan, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in links.keys():\n",
    "    if not k in product_mapping[\"col\"].tolist():\n",
    "        print(k, links[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only linked FADN codes\n",
    "product_mapping = product_mapping[~product_mapping[\"col\"].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fadn_codes_link = dict(zip(product_mapping[\"col\"], product_mapping[\"FADN Included products IDs\"], ))\n",
    "\n",
    "print(fadn_codes_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split metadata into area and holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_area = metadata[metadata[\"unit\"]==\"HA\"].reset_index(drop=True)\n",
    "metadata_holdings = metadata[metadata[\"unit\"]==\"HLD\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process area data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change crop code: From Eurostat code -> FADN code\n",
    "metadata_area[\"crops\"] = metadata_area.apply(lambda x: fadn_codes_link[x[\"crops\"]] if x[\"crops\"] in fadn_codes_link.keys() else x[\"crops\"], axis=1)\n",
    "\n",
    "# Select only identified FADN codes\n",
    "metadata_area = metadata_area[metadata_area.apply(lambda x: x[\"crops\"] in product_mapping[\"FADN Included products IDs\"].tolist(), axis=1)]\n",
    "\n",
    "metadata_area = metadata_area.drop(columns=[\"unit\"])\n",
    "\n",
    "metadata_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process holdings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    n_holdings_economic_size_filepath = \"./../../../../../mnt/c/users/idener/downloads/Poland-n_holdings-economic_size\"\n",
    "\n",
    "    n_holdings_df = pd.read_csv(os.path.join(n_holdings_economic_size_filepath, 'Poland-n_holdings-economic_size'), sep=\",|\\t\").rename(columns={\"2013 \": \"2013\", \"2016 \": \"2016\", })\n",
    "\n",
    "    economic_size_link = {\n",
    "        \"TOTAL\": \"Total\", \n",
    "        \"KE4-7\": \"From 4 000 to 7 999 euros\", \n",
    "        \"KE8-14\": \"From 8 000 to 14 999 euros\", \n",
    "        \"KE15-24\": \"From 15 000 to 24 999 euros\", \n",
    "        \"KE25-49\": \"From 25 000 to 49 999 euros\", \n",
    "        \"KE50-99\": \"From 50 000 to 99 999 euros\", \n",
    "        \"KE100-249\": \"From 100 000 to 249 999 euros\", \n",
    "        \"KE250-499\": \"From 250 000 to 499 999 euros\", \n",
    "        \"KE_GE500\": \"500 000 euros or over\", \n",
    "    }\n",
    "\n",
    "    n_holdings_df[\"so_eur\"] = n_holdings_df[\"so_eur\"].apply(lambda x: economic_size_link[x])\n",
    "\n",
    "    for year in [\"2013\", \"2016\", \"2020\", ]:\n",
    "        n_holdings_df[year] = n_holdings_df.apply(lambda x: x[year].replace(\" \", \"\").replace(\":\", \"0\"), axis=1)\n",
    "        n_holdings_df[year] = n_holdings_df[year].astype(int)\n",
    "\n",
    "\n",
    "    n_holdings_df[\"geo\\\\TIME_PERIOD\"] = n_holdings_df[\"geo\\\\TIME_PERIOD\"].apply(lambda x: x if x==NUTS2_code else NUTS2_code)\n",
    "\n",
    "    n_holdings_df = n_holdings_df.groupby(by=[\"so_eur\", \"unit\", \"freq\", \"uaarea\", \"crops\", \"geo\\TIME_PERIOD\"]).agg({\n",
    "        \"2013\": \"sum\", \n",
    "        \"2016\": \"sum\", \n",
    "        \"2020\": \"sum\"}\n",
    "    ).reset_index()[[\"so_eur\", \"unit\", \"2013\", \"2016\", \"2020\"]]\n",
    "\n",
    "\n",
    "    n_holdings_df = n_holdings_df.melt(id_vars=[\"so_eur\", \"unit\"],\n",
    "                    value_vars=[\"2013\", \"2016\", \"2020\"],\n",
    "                    var_name=\"YEAR\").pivot_table(values=\"value\",\n",
    "        index=[\"so_eur\", \"YEAR\", ],\n",
    "        columns=\"unit\",).reset_index().rename(columns={\n",
    "            \"so_eur\": 'Economic Size', \n",
    "            \"HA\": 'Hectare', \n",
    "            \"HLD\": 'Holding'\n",
    "        })[[\"YEAR\", \"Economic Size\", \"Hectare\", \"Holding\"]]\n",
    "\n",
    "    n_holdings_df.to_csv(\"./data/use_case_poland/metadata/number_of_holdings.csv\", index=False)\n",
    "\n",
    "    display(n_holdings_df)\n",
    "\n",
    "except:\n",
    "    print(\"Error loading data from downloads\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_holdings_economic = pd.read_csv(\"./data/use_case_poland/metadata/number_of_holdings.csv\")\n",
    "\n",
    "n_holdings_economic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_farms_sample_2013 = n_holdings_economic[(n_holdings_economic[\"YEAR\"]==2013)&(n_holdings_economic[\"Economic Size\"]!=\"Total\")][\"Holding\"].sum()\n",
    "print(n_farms_sample_2013)\n",
    "\n",
    "n_farms_sample_2016 = n_holdings_economic[(n_holdings_economic[\"YEAR\"]==2016)&(n_holdings_economic[\"Economic Size\"]!=\"Total\")][\"Holding\"].sum()\n",
    "print(n_farms_sample_2016)\n",
    "\n",
    "n_farms_sample_2020 = n_holdings_economic[(n_holdings_economic[\"YEAR\"]==2020)&(n_holdings_economic[\"Economic Size\"]!=\"Total\")][\"Holding\"].sum()\n",
    "print(n_farms_sample_2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_farms_sample_2014 = int(0.66*n_farms_sample_2013 + 0.33*n_farms_sample_2016)\n",
    "print(n_farms_sample_2014)\n",
    "\n",
    "n_farms_sample_2018 = int((n_farms_sample_2016 + n_farms_sample_2020)/2)\n",
    "print(n_farms_sample_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_farms_total_2013 = n_holdings_economic[(n_holdings_economic[\"YEAR\"]==2013)&(n_holdings_economic[\"Economic Size\"]==\"Total\")][\"Holding\"].sum()\n",
    "print(n_farms_total_2013)\n",
    "\n",
    "n_farms_total_2016 = n_holdings_economic[(n_holdings_economic[\"YEAR\"]==2016)&(n_holdings_economic[\"Economic Size\"]==\"Total\")][\"Holding\"].sum()\n",
    "print(n_farms_total_2016)\n",
    "\n",
    "n_farms_total_2020 = n_holdings_economic[(n_holdings_economic[\"YEAR\"]==2020)&(n_holdings_economic[\"Economic Size\"]==\"Total\")][\"Holding\"].sum()\n",
    "print(n_farms_total_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_farms_total_2014 = int(0.66*n_farms_total_2013 + 0.33*n_farms_total_2016)\n",
    "print(n_farms_total_2014)\n",
    "\n",
    "n_farms_total_2018 = int((n_farms_total_2016 + n_farms_total_2020)/2)\n",
    "print(n_farms_total_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_area[\"2014\"] = metadata_area.apply(lambda x: int(0.66*x[\"2013\"]+0.33*x[\"2016\"]), axis=1)\n",
    "metadata_area[\"2018\"] = metadata_area.apply(lambda x: x[[\"2016\", \"2020\"]].mean(), axis=1)\n",
    "metadata_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute average land per crop and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [\"2013\", \"2014\", \"2016\", \"2018\", \"2020\"]:\n",
    "    metadata_area[f\"avg {year}\"] = metadata_area.apply(lambda x: x[year]/eval(f\"n_farms_sample_{year}\"), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load microdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "microdata_2014 = pd.read_csv(\"./data/use_case_poland/microdata/PL2014.csv\")\n",
    "microdata_2018 = pd.read_csv(\"./data/use_case_poland/microdata/PL2018.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "microdata_2014 = microdata_2014[microdata_2014[\"A_LO_40_N2\"]==NUTS2_code].reset_index(drop=True)\n",
    "microdata_2018 = microdata_2018[microdata_2018[\"A_LO_40_N2\"]==NUTS2_code].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microdata_2018[[c for c in microdata_2014.columns if c.endswith(\"TA\")]].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area_variables = [var for var in [f\"I_A_{code}_TA\" for code in metadata_area[\"crops\"].unique()] if var in microdata_2014.columns]\n",
    "\n",
    "microdata_area_2014 = microdata_2014[total_area_variables].apply(lambda x: x/1, axis=1).copy(deep=True)\n",
    "microdata_area_2018 = microdata_2018[total_area_variables].apply(lambda x: x/1, axis=1).copy(deep=True)\n",
    "\n",
    "display(microdata_area_2014)\n",
    "display(microdata_area_2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_totals_2014 = metadata_area[metadata_area[\"crops\"].isin([int(var.replace(\"I_A_\", \"\").replace(\"_TA\", \"\")) for var in microdata_area_2014.columns])][\"avg 2014\"].to_numpy()\n",
    "mu_totals_2018 = metadata_area[metadata_area[\"crops\"].isin([int(var.replace(\"I_A_\", \"\").replace(\"_TA\", \"\")) for var in microdata_area_2018.columns])][\"avg 2018\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([mu_totals_2014, mu_totals_2018]).transpose().apply(lambda x: np.abs(x[0] - x[1]), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use empirical likelihood to compute weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2 import robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "# Instantiate R as a python object\n",
    "R = robjects.r\n",
    "\n",
    "# Load R function from script\n",
    "#with open(\"./src/R-scripts/R_functions.R\") as r_file:\n",
    "with open(\"./src/R-scripts/R_functions.R\") as r_file:\n",
    "    R_functions_string = r_file.read()\n",
    "\n",
    "# Convert text to R code\n",
    "R_functions = SignatureTranslatedAnonymousPackage(R_functions_string, \"R_functions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical likelihood ratio test for the means\n",
    "# weights is composed from\n",
    "#   {wts, nits}\n",
    "weights_2014_ = R_functions.el_test_function(microdata_area_2014, mu_totals_2014)\n",
    "weights_2014 = weights_2014_[5]\n",
    "\n",
    "weights_2018_ = R_functions.el_test_function(microdata_area_2018, mu_totals_2018)\n",
    "weights_2018 = weights_2018_[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(weights_2014, bins=100)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(weights_2018, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized weights for microdata rows\n",
    "# Use \"wts\" property from weights\n",
    "weights_norm_2014 = R_functions.normalize_weights(weights_2014_)\n",
    "weights_norm_2018 = R_functions.normalize_weights(weights_2018_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weights_2014 = pd.DataFrame(weights_norm_2014, columns=[\"A_TY_80_W\"]).apply(lambda x: x*n_farms_sample_2014)\n",
    "df_weights_2018 = pd.DataFrame(weights_norm_2018, columns=[\"A_TY_80_W\"]).apply(lambda x: x*n_farms_sample_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2014 = pd.concat([microdata_2014, df_weights_2014], axis=1)\n",
    "sample_2014.to_csv(os.path.join(microdata_path, \"PL2014.csv\"), index=False)\n",
    "sample_2018 = pd.concat([microdata_2018, df_weights_2018], axis=1)\n",
    "sample_2018.to_csv(os.path.join(microdata_path, \"PL2018.csv\"), index=False)\n",
    "\n",
    "#pd.concat([microdata_2014, df_weights_2014], axis=1).to_csv(os.path.join(microdata_path, \"CM2014.csv\"), index=False)\n",
    "#pd.concat([microdata_2018, df_weights_2018], axis=1).to_csv(os.path.join(microdata_path, \"CM2018.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2014[[c for c in sample_2014.columns if c.startswith(\"I_A_\") and c.endswith(\"_TA\")]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = pd.read_csv(\"./data/use_case_poland/metadata/Product_Mapping.csv\")\n",
    "\n",
    "display(pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Variable Name Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.VariableNameConversion import VariableNameConversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requested_number_of_farms = 1000\n",
    "USE_CASE = \"poland\"\n",
    "BASE_PATH = f\"./data/use_case_{USE_CASE}\"\n",
    "YEAR = \"2014\"\n",
    "TOTALS_VARIABLES = [\"cultivatedArea\"]\n",
    "\n",
    "vnc = VariableNameConversion(BASE_PATH, USE_CASE, YEAR, TOTALS_VARIABLES)\n",
    "\n",
    "sp_end, _, _ = vnc.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Crop Representativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "representativeness_2014 = pd.read_csv(\"./data/use_case_poland/results/FADN_Representativeness_2014.csv\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_2014 = representativeness_2014[representativeness_2014[\"fadn_code_organic\"].apply(lambda x: not \"ORG\" in x)].sort_values(by=[\"total_area\", \"production_quantity\"], ascending=False)\n",
    "\n",
    "rep_2014 = rep_2014[rep_2014[\"n_appearances_abs\"]>0]\n",
    "\n",
    "rep_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_grouping = {\n",
    "    \"CER\": [10150, 10110, 10130, 10190, 10140, \n",
    "            10170, 10120], \n",
    "    \"MAIZE\": [\n",
    "        10160, ],\n",
    "    \"BEET\": [10400, ], \n",
    "    \"OTHER\": [10601, 10602, 11000, 10923, \n",
    "              10603, 10604, 10605, 10607, 10608, 10609, 10610, 10611, 10612, 10613, 10690, 10810, 10820, 10830, 10840, 10850, 11100, 11210, 11220, 11300, 20000, 40330, 40340, 40411, 40412, 40420, 40451, 40452, 40460, 40470, 40480, 40500, 40600, 40610, 40700, 40800, 50100, 50200, 50210, 50900, 60000, 90100, 90200, 90300, 90310, 90320, 90330, 90900, \n",
    "              10735, 10737, 10734, 10711, 10712, 10720, 10731, 10732, 10733, 10736, 10790, # From VEG\n",
    "              ],\n",
    "    \"PROT\": [10290, 10210, 10220, \n",
    "                10606, 10922],\n",
    "    \"GRAZING\": [30100, 10921, 30200, \n",
    "                10500, 10910, 30300], \n",
    "    \"FRUITS\": [40111, \n",
    "               10738, 10739, 40112, 40113, 40114, 40115, 40120, 40130, 40210, 40220, 40230, 40290, 40310, 40320, 40430, 40440, ], \n",
    "    \"POTATO\": [10300, \n",
    "               10390, 10310 ],\n",
    "    }\n",
    "\n",
    "grouping = pd.DataFrame([(crop, group) for group in crops_grouping.keys() for crop in crops_grouping[group]], columns=[\"fadn_code\", \"product_group\"])\n",
    "\n",
    "grouping_dict = dict(zip(grouping[\"fadn_code\"], grouping[\"product_group\"]))\n",
    "grouping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_mapping_pol = product_mapping_and.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_mapping_pol[\"production type\"] = product_mapping_pol.apply(lambda x: \"organic\" if x[\"CUSTOM GROUP (EN)\"].startswith(\"ORG\") else \"conventional\", axis=1)\n",
    "product_mapping_pol[\"CUSTOM GROUP (EN)\"] = product_mapping_pol.apply(lambda x: grouping_dict[x[\"FADN Included products IDs\"]], axis=1)\n",
    "product_mapping_pol[\"CUSTOM GROUP (EN)\"] = product_mapping_pol.apply(lambda x: x[\"CUSTOM GROUP (EN)\"] if x[\"production type\"]==\"conventional\" else f'ORG_{x[\"CUSTOM GROUP (EN)\"]}', axis=1)\n",
    "\n",
    "product_mapping_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_mapping_pol.to_csv(\"./data/use_case_poland/metadata/Product_Mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_groups_and = pd.read_csv(\"./data/use_case_andalusia/metadata/Product_Groups.csv\")\n",
    "\n",
    "display(product_groups_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_categories = pd.DataFrame([cat for list_ in  product_groups_and[\"Categories\"].unique().tolist() for cat in eval(list_)]).drop_duplicates()[0].tolist()\n",
    "\n",
    "print(unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in product_mapping_pol[\"CUSTOM GROUP (EN)\"].unique():\n",
    "    print(f'\"{p}\": {unique_categories}, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_groups_pol_dict = {\n",
    "    \"CER\": ['Arable', 'Cereal', ], \n",
    "    \"MAIZE\": ['Arable', 'Cereal', ], \n",
    "    \"LEGUMES\": ['Arable', 'FixingNitrogen'], \n",
    "    \"POTATO\": ['Arable', ], \n",
    "    \"BEET\": ['Arable', ], \n",
    "    \"GRAZING\": ['Arable', 'LivestockFood', 'MeadowsAndPastures', ], \n",
    "    \"OTHER\": ['Arable', ], \n",
    "    \"FRUITS\": ['Perennial', ], \n",
    "\n",
    "    \"ORG_CER\": ['Arable', 'Cereal', ], \n",
    "    \"ORG_MAIZE\": ['Arable', 'Cereal', ], \n",
    "    \"ORG_LEGUMES\": ['Arable', 'FixingNitrogen'], \n",
    "    \"ORG_POTATO\": ['Arable', ], \n",
    "    \"ORG_BEET\": ['Arable', ], \n",
    "    \"ORG_GRAZING\": ['Arable', 'LivestockFood', 'MeadowsAndPastures', ], \n",
    "    \"ORG_OTHER\": ['Arable', ], \n",
    "    \"ORG_FRUITS\": ['Perennial', ], \n",
    "\n",
    "    \"OTHER_LIVESTOCK\":\t['OTHER'], \n",
    "    \"DAIRY\":           ['Arable', 'MILK'], \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_groups_pol = pd.DataFrame(zip(product_groups_pol_dict.keys(), product_groups_pol_dict.values()), columns=[\"PRODUCT GROUP\", \"Categories\"])\n",
    "\n",
    "product_groups_pol[\"Organic\"] = product_groups_pol.apply(lambda x: 1 if x[\"PRODUCT GROUP\"].startswith(\"ORG\") else 0, axis=1)\n",
    "\n",
    "product_groups_pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_groups_pol.to_csv(\"./data/use_case_poland/metadata/Product_Groups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(\"./..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_csv(\"./data/use_case_poland/microdata/POL2015.csv\")\n",
    "\n",
    "for c in [\"regionLevel1\", \"regionLevel1Name\", \"regionLevel2\", \"regionLevel2Name\", \"regionLevel3\", \"regionLevel3Name\", ]:\n",
    "    dd[c] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[\"regionLevel1\"] = \"PL81\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd__ = dd.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionLevelPoland():\n",
    "    def __init__(self, ):\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def _fill_regionLevel(self, sp):\n",
    "        \"\"\"\n",
    "        Assign district value based on experimental likelihood.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sp: pd.DataFrame\n",
    "            synthetic population\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        sp: pd.DataFrame\n",
    "            synthetic population with regionLevel and regionLevelName values filled\n",
    "        \"\"\"\n",
    "\n",
    "        nuts_info = pd.DataFrame([\n",
    "            [\"NUTS2\", \"PL81\",  \"Lubelskie\", 1, ],\n",
    "\n",
    "            [\"NUTS3\", \"PL811\", \"Bialski\",            0.25, ], \n",
    "            [\"NUTS3\", \"PL812\", \"Chełmsko-zamojski\",  0.25, ], \n",
    "            [\"NUTS3\", \"PL814\", \"Lubelski\",           0.25, ], \n",
    "            [\"NUTS3\", \"PL815\", \"Puławski\",           0.25, ], \n",
    "            \n",
    "            ], columns=[\"NUTS\", \"NUTS code\", \"NUTS name\", \"Number of holdings perc\"])\n",
    "\n",
    "        display(nuts_info)\n",
    "\n",
    "        \n",
    "        #n_farms_real = sample_2014[\"A_TY_80_W\"].sum().astype(int)\n",
    "        n_farms_real = sp.shape[0]\n",
    "        \n",
    "        # Total number of farms\n",
    "        print(f'Total Number of farms according to microdata in year 2014: {n_farms_real}')\n",
    "\n",
    "        nuts2_info = nuts_info[nuts_info[\"NUTS\"]==\"NUTS2\"]\n",
    "        nuts2_link_dict = dict(zip(nuts2_info[\"NUTS code\"].tolist(), nuts2_info[\"NUTS name\"].tolist(), ))\n",
    "\n",
    "        nuts3_info = nuts_info[nuts_info[\"NUTS\"]==\"NUTS3\"]\n",
    "        nuts3_link_dict = dict(zip(nuts3_info[\"NUTS code\"].tolist(), nuts3_info[\"NUTS name\"].tolist(), ))\n",
    "\n",
    "        values = nuts3_info[\"NUTS code\"].tolist()\n",
    "        probabilities = nuts3_info[\"Number of holdings perc\"].tolist()\n",
    "\n",
    "        # Assignation regionLevel1\n",
    "        sp[\"regionLevel1Name\"] = sp.apply(lambda x: nuts2_link_dict[x[\"regionLevel1\"]], axis=1)\n",
    "\n",
    "        # Assignation regionLevel2\n",
    "        sp[\"regionLevel2\"] = np.random.choice(values, n_farms_real, p=probabilities)\n",
    "        sp[\"regionLevel2Name\"] = sp.apply(lambda x: nuts3_link_dict[x[\"regionLevel2\"]], axis=1)\n",
    "\n",
    "        # Assignation regionLevel3\n",
    "        # Divide data in 5\n",
    "        n_rl3 = 5\n",
    "\n",
    "        print(\".-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-\")\n",
    "        for rl2 in sp[\"regionLevel2\"].unique():\n",
    "            indexes = sp[sp[\"regionLevel2\"]==rl2].index\n",
    "\n",
    "            values = [f\"{rl2}{i}\" for i in range(1, 1+n_rl3)]\n",
    "            probabilities = [1/n_rl3]*n_rl3\n",
    "\n",
    "            sp.loc[indexes, \"regionLevel3\"] = np.random.choice(values, len(indexes), p=probabilities)\n",
    "            \n",
    "\n",
    "        sp[\"regionLevel3Name\"] = sp.apply(lambda x: x[\"regionLevel3\"], axis=1)\n",
    "\n",
    "        # regionLevel must be an integer\n",
    "        for rl in [1, 2, 3]:\n",
    "            sp[f\"regionLevel{rl}\"] = sp.apply(lambda x: int(x[f\"regionLevel{rl}\"].replace(\"PL\", \"\")), axis=1)\n",
    "\n",
    "        \n",
    "        return sp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlp = RegionLevelPoland()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = rlp._fill_regionLevel(dd__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"regionLevel1\", \"regionLevel1Name\", \"regionLevel2\", \"regionLevel2Name\", \"regionLevel3\", \"regionLevel3Name\", ]:\n",
    "    print(c, rr[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agricore_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
